# ğŸ“„ PDF Retrieval-Augmented Generation (RAG)  

A **Retrieval-Augmented Generation (RAG)** pipeline for interacting with PDF documents.  
This project lets you upload PDFs, store them in a **Qdrant vector database**, and ask questions about the content using **OpenAIâ€™s API** with **LlamaIndex** as the orchestration layer.  

It also integrates with **Inngest** for background event-driven processing and uses **FastAPI** as the backend framework.  

---

## ğŸš€ Features  
- ğŸ“‚ **PDF Ingestion** â†’ Upload and parse PDFs.  
- ğŸ§© **Chunking & Embeddings** â†’ Split PDFs into text chunks using LlamaIndex and embed them.  
- ğŸ“¦ **Vector Store** â†’ Store embeddings in **Qdrant** for fast semantic search.  
- ğŸ¤– **RAG Pipeline** â†’ Retrieve relevant chunks and augment prompts for the OpenAI API.  
- âš¡ **FastAPI Backend** â†’ Serve endpoints for uploading, querying, and interacting.  
- ğŸª„ **Inngest Integration** â†’ Handle background tasks like ingestion events.  

---

## ğŸ› ï¸ Tech Stack  
- **Python** â†’ Core language  
- **FastAPI** â†’ Web framework  
- **Inngest** â†’ Event-driven workflow orchestration  
- **Qdrant** â†’ Vector database  
- **OpenAI API** â†’ Large Language Model for answering queries  
- **LlamaIndex** â†’ Document parsing, chunking, and retrieval orchestration  

---
